<html><head><title></title>
</head>
<body bgcolor=#ffffff>
<hr>
<h1>Chapter 11: Playing, Recording and Editing MIDI Sequences</h1>
<hr>
<form name="form1">
  <select name="menu1" onChange="Eminem_jumpMenu('parent',this,1)">
    <SCRIPT SRC="menu_script.js" language="JavaScript"></SCRIPT>
  </select>
</form>
<p>&nbsp;</p>
<p><a name="120888"> </a>
In the world of MIDI, a <em>sequencer</em> is any hardware or software device that can precisely play or record a <em>sequence</em> of time-stamped MIDI messages. Similarly, in the Java<font size="-1"><sup>TM</sup></font> Sound API, the <code>Sequencer</code> abstract interface defines the properties of an object that can play and record <code>Sequences</code> of <code>MidiEvent</code> objects. A <code>Sequencer</code> typically loads these <code>MidiEvent</code> sequences from a standard MIDI file or saves them to such a file. Sequences can also be edited. This chapter explains how to use <code>Sequencer</code> objects, along with related classes and interfaces, to accomplish such tasks.
</p><a name="120890"> </a>
<h3> Introduction to Sequencers</h3>
<p><a name="120892"> </a>
To develop an intuitive understanding of what a <code>Sequencer</code> is, think of it by analogy with a tape recorder, which a sequencer resembles in many respects. Whereas a tape recorder plays audio, a sequencer plays MIDI data. A sequence is a multi-track, linear, time-ordered recording of MIDI musical data, which a sequencer can play at various speeds, rewind, shuttle to particular points, record into, or copy to a file for storage.
</p>
<p><a name="124503"> </a> Chapter 10, "<a href="chapter10.html">Transmitting and 
  Receiving MIDI Messages</a>," explained that devices typically have <code>Receiver</code> 
  objects, <code>Transmitter</code> objects, or both. To <em>play </em>music, 
  a device generally receives <code>MidiMessages</code> through a <code>Receiver</code>, 
  which in turn has usually received them from a <code>Transmitter</code> that 
  belongs to a <code>Sequencer</code>. The device that owns this <code>Receiver</code> 
  might be a <code>Synthesizer</code>, which will generate audio directly, or 
  it might be a MIDI output port, which transmits MIDI data through a physical 
  cable to some external piece of equipment. Similarly, to <em>record </em>music, 
  a series of time-stamped <code>MidiMessages</code> are generally sent to a <code>Receiver</code> 
  owned by a <code>Sequencer</code>, which places them in a <code>Sequence</code> 
  object. Typically the object sending the messages is a <code>Transmitter</code> 
  associated with a hardware input port, and the port relays MIDI data that it 
  gets from an external instrument. However, the device responsible for sending 
  the messages might instead be some other <code>Sequencer</code>, or any other 
  device that has a <code>Transmitter</code>. Furthermore, as mentioned in Chapter 
  10, a program can send messages without using any <code>Transmitter </code>at 
  all. </p>
<p><a name="120896"> </a>
A <code>Sequencer</code> itself has both <code>Receivers</code> and <code>Transmitters</code>. When it's recording, it actually obtains <code>MidiMessages</code> via its <code>Receivers</code>. During playback, it uses its <code>Transmitters</code> to send <code>MidiMessages</code> that are stored in the <code>Sequence</code> that it has recorded (or loaded from a file).
</p><p><a name="124511"> </a>
One way to think of the role of a <code>Sequencer</code> in the Java Sound API is as an aggregator and "de-aggregator" of <code>MidiMessages</code>. A series of separate <code>MidiMessages</code>, each of which is independent, is sent to the <code>Sequencer</code> along with its own time stamp that marks the timing of a musical event. These <code>MidiMessages</code> are encapsulated in <code>MidiEvent</code> objects and collected in <code>Sequence</code> objects through the action of the <code>Sequencer.record</code> method. A <code>Sequence</code> is a data structure containing aggregates of <code>MidiEvents</code>, and it usually represents a series of musical notes, often an entire song or composition. On playback, the <code>Sequencer</code> again extracts the <code>MidiMessages</code> from the <code>MidiEvent</code> objects in the <code>Sequence</code> and then transmits them to one or more devices that will either render them into sound, save them, modify them, or pass them on to some other device.
</p>
<p><a name="124522"> </a> Some sequencers might have neither transmitters nor 
  receivers. For example, they might create <code>MidiEvents </code>from scratch 
  as a result of keyboard or mouse events, instead of receiving <code>MidiMessages</code> 
  through <code>Receivers</code>. Similarly, they might play music by communicating 
  directly with an internal synthesizer (which could actually be the same object 
  as the sequencer) instead of sending <code>MidiMessages</code> to a <code>Receiver 
  </code>associated with a separate object. However, the rest of this chapter 
  assumes the normal case of a sequencer that uses <code>Receivers</code> and 
  <code>Transmitters</code>. </p>
<a name="when"></a>
<h4> When to Use a Sequencer</h4>
<p><a name="124536"> </a> It's possible for an application program to send MIDI 
  messages directly to a device, without using a sequencer, as was described in 
  Chapter 10, "<a href="chapter10.html">Transmitting and Receiving MIDI Messages</a>." 
  The program simply invokes the <code>Receiver.send</code> method each time it 
  wants to send a message. This is a straightforward approach that's useful when 
  the program itself creates the messages in real time. For example, consider 
  a program that lets the user play notes by clicking on an onscreen piano keyboard. 
  When the program gets a mouse-down event, it immediately sends the appropriate 
  Note On message to the synthesizer. </p>
<p><a name="124540"> </a>
As mentioned in Chapter 10, the program can include a time stamp with each MIDI message it sends to the device's receiver. However, such time stamps are used only for fine-tuning the timing, to correct for processing latency. The caller can't generally set arbitrary time stamps; the time value passed to <code>Receiver.send</code> must be close to the present time, or the receiving device might not be able to schedule the message correctly. This means that if an application program wanted to create a queue of MIDI messages for an entire piece of music ahead of time (instead of creating each message in response to a real-time event), it would have to be very careful to schedule each invocation of <code>Receiver.send</code> for nearly the right time. 
</p>
<p><a name="124541"> </a> Fortunately, most application programs don't have to 
  be concerned with such scheduling. Instead of invoking <code>Receiver.send</code> 
  itself, a program can use a <code>Sequencer</code> object to manage the queue 
  of MIDI messages for it. The sequencer takes care of scheduling and sending 
  the messages&#151;in other words, playing the music with the correct timing. 
  Generally, it's advantageous to use a sequencer whenever you need to convert 
  a non-real-time series of MIDI messages to a real-time series (as in playback), 
  or vice versa (as in recording). Sequencers are most commonly used for playing 
  data from MIDI files and for recording data from a MIDI input port. </p>
<a name="124542"> </a>
<h3> Understanding Sequence Data </h3>
<p><a name="124543"> </a>
Before examining the <code>Sequencer</code> API, it helps to understand the kind of data that's stored in a sequence. 
</p><a name="124544"> </a>
<h4> Sequences and Tracks</h4>
<p><a name="124545"> </a>
In the Java Sound API, sequencers closely follow the Standard MIDI Files specification in the way that they organize recorded MIDI data. As mentioned above, a <code>Sequence</code> is an aggregation of <code>MidiEvents</code>, organized in time. But there is more structure to a <code>Sequence</code> than just a linear series of <code>MidiEvents</code>: a <code>Sequence</code> actually contains global timing information plus a collection of <code>Tracks</code>, and it is the <code>Tracks</code> themselves that hold the <code>MidiEvent</code> data. So the data played by a sequencer consists of a three-level hierarchy of objects: <code>Sequencer</code>, <code>Track</code>, and <code>MidiEvent</code>.
</p><p><a name="124546"> </a>
In the conventional use of these objects, the <code>Sequence</code> represents a complete musical composition or section of a composition, with each <code>Track</code> corresponding to a voice or player in the ensemble. In this model, all the data on a particular <code>Track</code> would also therefore be encoded into a particular MIDI channel reserved for that voice or player.
</p>
<p><a name="124547"> </a> This way of organizing data is convenient for purposes 
  of editing sequences, but note that this is just a conventional way to use <code>Tracks</code>. 
  There is nothing in the definition of the <code>Track</code> class per se that 
  keeps it from containing a mix of <code>MidiEvents</code> on different MIDI 
  channels. For example, an entire multi-channel MIDI composition can be mixed 
  and recorded onto one <code>Track</code>. Also, standard MIDI files of Type 
  0 (as opposed to Type 1 and Type 2) contain by definition only one track; so 
  a <code>Sequence</code> that's read from such a file will necessarily have a 
  single <code>Track</code> object. </p>
<a name="124548"> </a>
<h4> MidiEvents and Ticks</h4>
<p><a name="124552"> </a> As discussed in Chapter 8, "<a href="chapter8.html">Overview 
  of the MIDI Package</a>," the Java Sound API includes <code>MidiMessage</code> 
  objects that correspond to the raw two- or three-byte sequences that make up 
  most standard MIDI messages. A <code>MidiEvent</code> is simply a packaging 
  of a <code>MidiMessage</code> along with an accompanying timing value that specifies 
  when the event occurs. (We might then say that a sequence really consists of 
  a four- or five-level hierarchy of data, rather than three-level, because the 
  ostensible lowest level, <code>MidiEvent</code>, actually contains a lower-level 
  <code>MidiMessage</code>, and likewise the <code>MidiMessage</code> object contains 
  an array of bytes that comprises a standard MIDI message.) </p>
<p><a name="124553"> </a> In the Java Sound API, there are two different ways 
  in which <code>MidiMessages</code> can be associated with timing values. One 
  is the way mentioned above under "<a href="chapter11.html#when">When to Use 
  a Sequencer</a>." This technique is described in detail under "<a href="chapter10.html#sending">Sending 
  a Message to a Receiver without Using a Transmitter</a>" and "<a href="chapter10.html#understanding_time">Understanding 
  Time Stamps</a>" in Chapter 10, "<a href="chapter10.html">Transmitting and Receiving 
  MIDI Messages</a>." There, we saw that the <code>send</code> method of <code>Receiver</code> 
  takes a <code>MidiMessage</code> argument and a time-stamp argument. That kind 
  of time stamp can only be expressed in microseconds. </p>
<p><a name="124566"> </a>
The other way in which a <code>MidiMessage</code> can have its timing specified is by being encapsulated in a <code>MidiEvent</code>. In this case, the timing is expressed in slightly more abstract units called <em>ticks</em>. 
</p>
<p><a name="124567"> </a> What is the duration of a tick? It can vary between 
  sequences (but not within a sequence), and its value is stored in the header 
  of a standard MIDI file. The size of a tick is given in one of two types of 
  units: </p>
<ul><a name="124568"> </a>
<li>Pulses (ticks) per quarter note, abbreviated as PPQ
<a name="124569"> </a>
<li>Ticks per frame, also known as SMPTE time code (a standard adopted by the Society of Motion Picture and Television Engineers)
<p><a name="124570"> </a>
</ul>
 If the unit is PPQ, the size of a tick is expressed as a fraction of a quarter note, which is a relative, not absolute, time value. A quarter note is a musical duration value that often corresponds to one beat of the music (a quarter of a measure in 4/4 time). The duration of a quarter note is dependent on the tempo, which can vary during the course of the music if the sequence contains tempo-change events. So if the sequence's timing increments (ticks) occur, say 96 times per quarter note, each event's timing value measures that event's position in musical terms, not as an absolute time value. 
<p></p><p><a name="124571"> </a>
On the other hand, in the case of SMPTE, the units measure absolute time, and the notion of tempo is inapplicable. There are actually four different SMPTE conventions available, which refer to the number of motion-picture frames per second. The number of frames per second can be 24, 25, 29.97, or 30. With SMPTE time code, the size of a tick is expressed as a fraction of a frame.
</p>
<p><a name="124572"> </a> In the Java Sound API, you can invoke <code>Sequence.getDivisionType</code> 
  to learn which type of unit&#151;namely, PPQ or one of the SMPTE units&#151;is 
  used in a particular sequence. You can then calculate the size of a tick after 
  invoking <code>Sequence.getResolution</code>. The latter method returns the 
  number of ticks per quarter note if the division type is PPQ, or per SMPTE frame 
  if the division type is one of the SMPTE conventions. You can get the size of 
  a tick using this formula in the case of PPQ: </p>
<blockquote><pre>
ticksPerSecond =  
    resolution * (currentTempoInBeatsPerMinute / 60.0);
tickSize = 1.0 / ticksPerSecond;
</pre></blockquote>
<p><a name="124576"> </a>
and this formula in the case of SMPTE:
<blockquote><pre>
framesPerSecond = 
  (divisionType == Sequence.SMPTE_24 ? 24
    : (divisionType == Sequence.SMPTE_25 ? 25
      : (divisionType == Sequence.SMPTE_30 ? 30
        : (divisionType == Sequence.SMPTE_30DROP ?<br>
            29.97))));
ticksPerSecond = resolution * framesPerSecond;
tickSize = 1.0 / ticksPerSecond;
</pre></blockquote>
<p><a name="124584"> </a>
The Java Sound API's definition of timing in a sequence mirrors that of the Standard MIDI Files specification. However, there's one important difference. The tick values contained in <code>MidiEvents</code> measure <em>cumulative</em> time, rather than <em>delta</em> time. In a standard MIDI file, each event's timing information measures the amount of time elapsed since the onset of the previous event in the sequence.   This is called delta time. But in the Java Sound API, the ticks aren't delta values; they're the previous event's time value <em>plus</em> the delta value.   In other words, in the Java Sound API the timing value for each event is always greater than that of the previous event in the sequence (or equal, if the events are supposed to be simultaneous). Each event's timing value measures the time elapsed since the beginning of the sequence.
</p><p><a name="124585"> </a>
To summarize, the Java Sound API expresses timing information in either MIDI ticks or microseconds. <code>MidiEvents</code> store timing information in terms of MIDI ticks. The duration of a tick can be calculated from the <code>Sequence's</code> global timing information and, if the sequence uses tempo-based timing, the current musical tempo. The time stamp associated with a <code>MidiMessage</code> sent to a <code>Receiver</code>, on the other hand, is always expressed in microseconds.
</p><p><a name="124586"> </a>
One goal of this design is to avoid conflicting notions of time. It's the job of a <code>Sequencer</code> to interpret the time units in its <code>MidiEvents</code>, which might have PPQ units, and translate these into absolute time in microseconds, taking the current tempo into account. The sequencer must also express the microseconds relative to the time when the device receiving the message was opened. Note that a sequencer can have multiple transmitters, each delivering messages to a different receiver that might be associated with a completely different device. You can see, then, that the sequencer has to be able to perform multiple translations at the same time, making sure that each device receives time stamps appropriate for its notion of time. 
</p>
<p><a name="124587"> </a> To make matters more complicated, different devices 
  might update their notions of time based on different sources (such as the operating 
  system's clock, or a clock maintained by a sound card). This means that their 
  timings can drift relative to the sequencer's. To keep in synchronization with 
  the sequencer, some devices permit themselves to be "slaves" to the sequencer's 
  notion of time. Setting masters and slaves is discussed later under "<a href="chapter11.html#124684">Using 
  Advanced Sequencer Features</a>." </p>
<a name="124591"> </a>
<h3> Overview of Sequencer Methods</h3>
<p><a name="124592"> </a>
The <code>Sequencer</code> interface provides methods in several categories:
</p><ul><a name="124593"> </a>
<li>Methods to load sequence data from a MIDI file or a <code>Sequence</code> object, and to save the currently loaded sequence data to a MIDI file.
<a name="124594"> </a>
<li>Methods analogous to the transport functions of a tape recorder, for stopping and starting playback and recording, enabling and disabling recording on specific tracks, and shuttling the current playback or recording position in a <code>Sequence</code>.
<a name="124595"> </a>
<li>Advanced methods for querying and setting the synchronization and timing parameters of the object. A <code>Sequencer</code> may play at different tempos, with some <code>Tracks</code> muted, and in various synchronization states with other objects.
<a name="124596"> </a>
<li>Advanced methods for registering "listener" objects that are notified when the <code>Sequencer</code> processes certain kinds of MIDI events.
<p><a name="124597"> </a>
</ul>
Regardless of which <code>Sequencer </code>methods you'll invoke, the first step is to obtain a <code>Sequencer</code> device from the system and reserve it for your program's use.
<p></p><a name="124598"> </a>
<h3> Obtaining a Sequencer</h3>
<p><a name="124599"> </a> An application program doesn't instantiate a <code>Sequencer</code>; 
  after all, <code>Sequencer</code> is just an interface. Instead, like all devices 
  in the Java Sound API's MIDI package, a <code>Sequencer</code> is accessed through 
  the static <code>MidiSystem</code> object. As mentioned in Chapter 9, "<a href="chapter9.html">Accessing 
  MIDI System Resources</a>," the following <code>MidiSystem</code> method can 
  be used to obtain the default <code>Sequencer</code>: </p>
<blockquote><pre>    static Sequencer getSequencer()
</pre></blockquote>
<p><a name="124604"> </a>
The following code fragment obtains the default<code> Sequencer</code>, acquires any system resources it needs, and makes it operational:
<blockquote><pre>
    Sequencer sequencer;
    // Get default sequencer.
    sequencer = MidiSystem.getSequencer(); 
    if (sequencer == null) {
        // Error -- sequencer device is not supported.
        // Inform user and return...
    } else {
         // Acquire resources and make operational.
        sequencer.open();
    }
	</pre></blockquote>
<p><a name="124615"> </a>
The invocation of <code>open</code> reserves the sequencer device for your program's use. It doesn't make much sense to imagine sharing a sequencer, because it can play only one sequence at a time. When you're done using the sequencer, you can make it available to other programs by invoking <code>close</code>.
</p>
<p><a name="124616"> </a> Non-default sequencers can be obtained as described 
  in Chapter 9, "<a href="chapter9.html">Accessing MIDI System Resources</a>." 
</p>
<a name="124620"> </a>
<h3> Loading a Sequence</h3>
<p><a name="124621"> </a>
Having obtained a sequencer from the system and reserved it, you then need load the data that the sequencer should play. There are three typical ways of accomplishing this:
</p><ul><a name="124622"> </a>
<li>Reading the sequence data from a MIDI file
<a name="124623"> </a>
<li>Recording it in real time by receiving MIDI messages from another device, such as a MIDI input port
<a name="124624"> </a>
<li>Building it programmatically "from scratch" by adding tracks to an empty sequence and adding <code>MidiEvent</code> objects to those tracks
<p><a name="124625"> </a>
</ul>
We'll now look at the first of these ways of getting sequence data. (The other 
two ways are described later under "<a href="chapter11.html#124654">Recording 
and Saving Sequences</a>" and "<a href="chapter11.html#124674">Editing a Sequence</a>," 
respectively.) This first way actually encompasses two slightly different approaches. 
One approach is to feed MIDI file data to an <code>InputStream</code> that you 
then read directly to the sequencer by means of <code>Sequencer.setSequence(InputStream)</code>. 
With this approach, you don't explicitly create a <code>Sequence</code> object. 
In fact, the <code>Sequencer</code> implementation might not even create a <code>Sequence</code> 
behind the scenes, because some sequencers have a built-in mechanism for handling 
data directly from a file. 
<p></p>
<p><a name="124632"> </a> The other approach is to create a <code>Sequence</code> 
  explicitly. You'll need to use this approach if you're going to edit the sequence 
  data before playing it. With this approach, you invoke <code>MidiSystem's</code> 
  overloaded method <code>getSequence</code>. The method is able to get the sequence 
  from an <code>InputStream</code>, a <code>File</code>, or a <code>URL</code>. 
  The method returns a <code>Sequence</code> object that can then be loaded into 
  a <code>Sequencer</code> for playback. Expanding on the previous code excerpt, 
  here's an example of obtaining a <code>Sequence</code> object from a <code>File</code> 
  and loading it into our <code>sequencer</code>: </p>
<blockquote><pre>    try {
        File myMidiFile = new File("seq1.mid");
        // Construct a Sequence object, and
        // load it into my sequencer.
         Sequence mySeq = MidiSystem.getSequence(myMidiFile);
        sequencer.setSequence(mySeq);
    } catch (Exception e) {
        // Handle error and/or return
    }
	</pre></blockquote>
<p><a name="124642"> </a> Like <code>MidiSystem's</code> <code>getSequence</code> 
  method, <code>setSequence</code> may throw an <code>InvalidMidiDataException</code>&#151;and, 
  in the case of the <code>InputStream</code> variant, an <code>IOException</code>&#151;if 
  it runs into any trouble. </p>
<a name="124643"> </a>
<h3> Playing a Sequence</h3>
<p><a name="124644"> </a>
Starting and stopping a <code>Sequencer</code> is accomplished using the following methods:
</p><blockquote><pre>    void start()
</pre></blockquote>
<p><a name="124646"> </a>
and
<blockquote><pre>    void stop()
</pre></blockquote>
<p><a name="124648"> </a>
The <code>Sequencer.start</code> method begins playback of the sequence. Note that playback starts at the current position in a sequence. Loading an existing sequence using the <code>setSequence</code> method, described above, initializes the sequencer's current position to the very beginning of the sequence. The <code>stop</code> method stops the sequencer, but it does not automatically rewind the current <code>Sequence</code>. Starting a stopped <code>Sequence</code> without resetting the position simply resumes playback of the sequence from the current position. In this case, the <code>stop</code> method has served as a pause operation. However, there are various <code>Sequencer</code> methods for setting the current sequence position to an arbitrary value before playback is started. (We'll discuss these methods below.)
</p>
<p><a name="124649"> </a> As mentioned earlier, a <code>Sequencer</code> typically 
  has one or more <code>Transmitter</code> objects, through which it sends <code>MidiMessages</code> 
  to a <code>Receiver</code>. It is through these <code>Transmitters</code> that 
  a <code>Sequencer</code> plays the <code>Sequence</code>, by emitting appropriately 
  timed <code>MidiMessages</code> that correspond to the <code>MidiEvents</code> 
  contained in the current <code>Sequence</code>. Therefore, part of the setup 
  procedure for playing back a <code>Sequence</code> is to invoke the <code>setReceiver</code> 
  method on the <code>Sequencer's</code> <code>Transmitter</code> object, in effect 
  wiring its output to the device that will make use of the played-back data. 
  For more details on <code>Transmitters</code> and <code>Receivers</code>, see 
  Chapter 10, "<a href="chapter10.html">Transmitting and Receiving MIDI Messages</a>." 
</p>
<a name="124654"> </a>
<h3> Recording and Saving Sequences</h3>
<p><a name="124655"> </a>
To capture MIDI data to a <code>Sequence</code>, and subsequently to a file, you need to perform some additional steps beyond those described above. The following outline shows the steps necessary to set up for recording to a <code>Track</code> in a <code>Sequence</code>:
</p><ol>
<a name="124656"> </a>
<li>Use <code>MidiSystem.getSequencer</code> to get a new sequencer to use for recording, as above. 
<a name="124657"> </a>
<p>
<li>Set up the "wiring" of the MIDI connections. The object that is transmitting the MIDI data to be recorded should be configured, through its <code>setReceiver</code> method, to send data to a <code>Receiver</code> associated with the recording <code>Sequencer</code>.
<a name="124658"> </a>
<p>
<li>Create a new <code>Sequence</code> object, which will store the recorded data. When you create the <code>Sequence</code> object, you must specify the global timing information for the sequence. For example:
<blockquote><pre>      Sequence mySeq;
      try{
          mySeq = new Sequence(Sequence.PPQ, 10);
      } catch (Exception ex) { 
          ex.printStackTrace(); 
      }
</pre></blockquote>
<a name="124666"> </a>
The constructor for <code>Sequence</code> takes as arguments a <code>divisionType</code> and a timing resolution. The <code>divisionType</code> argument specifies the units of the resolution argument. In this case, we've specified that the timing resolution of the <code>Sequence</code> we're creating will be 10 pulses per quarter note. An additional optional argument to the <code>Sequence</code> constructor is a number of tracks argument, which would cause the initial sequence to begin with the specified number of (initially empty) <code>Tracks</code>. Otherwise the <code>Sequence</code> will be created with no initial <code>Tracks</code>; they can be added later as needed.
<a name="124667"> </a>
<p>
<li>Create an empty <code>Track</code> in the <code>Sequence</code>, with <code>Sequence.createTrack</code>. This step is unnecessary if the <code>Sequence</code> was created with initial <code>Tracks</code>.
<a name="124668"> </a>
<p>
<li>Using <code>Sequencer.setSequence</code>, select our new <code>Sequence</code> to receive the recording. The <code>setSequence</code> method ties together an existing <code>Sequence</code> with the <code>Sequencer</code>, which is somewhat analogous to loading a tape onto a tape recorder. 
<a name="124669"> </a>
<p>
<li>Invoke <code>Sequencer.recordEnable</code> for each <code>Track</code> to be recorded. If necessary, get a reference to the available <code>Tracks</code> in the <code>Sequence</code> by invoking <code>Sequence.getTracks</code>.
<a name="124670"> </a>
<p>
<li>Invoke <code>startRecording</code> on the <code>Sequencer</code>.
<a name="124671"> </a>
<p>
<li>When done recording, invoke <code>Sequencer.stop</code> or <code>Sequencer.stopRecording</code>.
<a name="124672"> </a>
<p>
<li>Save the recorded <code>Sequence</code> to a MIDI file with <code>MidiSystem.write</code>. The <code>write</code> method of <code>MidiSystem</code> takes a <code>Sequence</code> as one of its arguments, and will write that <code>Sequence</code> to a stream or file. 
</ol>
<a name="124674"> </a>
<h3> Editing a Sequence</h3>
<p><a name="124675"> </a>
Many application programs allow a sequence to be created by loading it from a file, and quite a few also allow a sequence to be created by capturing it from live MIDI input (that is, recording). Some programs, however, will need to create MIDI sequences from scratch, whether programmatically or in response to user input. Full-featured sequencer programs permit the user to manually construct new sequences, as well as to edit existing ones. 
</p><p><a name="124676"> </a>
These data-editing operations are achieved in the Java Sound API not by <code>Sequencer</code> methods, but by methods of the data objects themselves: <code>Sequence</code>, <code>Track</code>, and <code>MidiEvent</code>. You can create an empty sequence using one of the <code>Sequence</code> constructors, and then add tracks to it by invoking the following <code>Sequence</code> method:
</p><blockquote><pre>    Track createTrack() 
<p><a name="124678"> </a>
</pre></blockquote>
If your program allows the user to edit sequences, you'll need this <code>Sequence</code> method to remove tracks:
<blockquote><pre>    boolean deleteTrack(Track track) 
</pre></blockquote>
<p><a name="124680"> </a>
Once the sequence contains tracks, you can modify the contents of the tracks by invoking methods of the <code>Track</code> class. The <code>MidiEvents</code> contained in the <code>Track</code> are stored as a<code> java.util.Vector</code> in the <code>Track</code> object, and <code>Track</code> provides a set of methods for accessing, adding, and removing the events in the list. The methods <code>add</code> and <code>remove</code> are fairly self-explanatory, adding or removing a specified <code>MidiEvent</code> from a <code>Track</code>. A <code>get</code> method is provided, which takes an index into the <code>Track's</code> event list and returns the <code>MidiEvent</code> stored there. In addition, there are <code>size</code> and <code>tick</code> methods, which respectively return the number of <code>MidiEvents</code> in the track, and the track's duration, expressed as a total number of <code>Ticks</code>.
</p><p><a name="124681"> </a>
To create a new event before adding it to the track, you'll of course use the <code>MidiEvent</code> constructor. To specify or modify the MIDI message embedded in the event, you can invoke the <code>setMessage</code> method of the appropriate <code>MidiMessage</code> subclass (<code>ShortMessage</code>, <code>SysexMessage</code>, or <code>MetaMessage</code>). To modify the time that the event should occur, invoke <code>MidiEvent.setTick</code>.
</p><p><a name="124682"> </a>
In combination, these low-level methods provide the basis for the editing functionality needed by a full-featured sequencer program.
</p>
<a name="124684"> </a> 
<h3> Using Advanced Sequencer Features</h3>
<p><a name="124685"> </a>
So far, this chapter has focused on simple playback and recording of MIDI data. This section will briefly describe some of the more advanced features available through methods of the <code>Sequencer</code> interface and the <code>Sequence</code> class. 
</p><a name="124686"> </a>
<h4> Moving to an Arbitrary Position in the Sequence </h4>
<p><a name="124687"> </a>
There are two <code>Sequencer</code> methods that obtain the sequencer's current position in the sequence. The first of these: 
</p><blockquote><pre>    long getTickPosition()
</pre></blockquote>
<p><a name="124689"> </a>
returns the position measured in MIDI ticks from the beginning of the sequence. The second method: 
<blockquote><pre>long getMicrosecondPosition()
</pre></blockquote>
<p><a name="124691"> </a>
returns the current position in microseconds. This method assumes that the sequence is being played at the default rate as stored in the MIDI file or in the <code>Sequence</code>. It does <em>not </em>return a different value if you've changed the playback speed as described below. 
</p><p><a name="124692"> </a>
You can similarly set the sequencer's current position according to one unit or the other:
<blockquote><pre>void setTickPosition(long tick)
</pre></blockquote>
<p><a name="124694"> </a>
or 
<blockquote><pre>void setMicrosecondPosition(long microsecond)
</pre></blockquote><a name="124696"> </a>
<h4> Changing the Playback Speed </h4>
<p><a name="124697"> </a>
As indicated earlier, a sequence's speed is indicated by its tempo, which can vary over the course of the sequence. A sequence can contain events that encapsulate standard MIDI tempo-change messages. When the sequencer processes such an event, it changes the speed of playback to reflect the indicated tempo. In addition, you can programmatically change the tempo by invoking any of these <code>Sequencer</code> methods:
</p><blockquote><pre>    public void setTempoInBPM(float bpm)
    public void setTempoInMPQ(float mpq)
    public void setTempoFactor(float factor)
</pre></blockquote>
The first two of these methods set the tempo in beats per minute or microseconds per quarter note, respectively. The tempo will stay at the specified value until one of these methods is invoked again, or until a tempo-change event is encountered in the sequence, at which point the current tempo is overridden by the newly specified one.
<p></p><p><a name="124702"> </a>
The third method, <code>setTempoFactor</code>, is different in nature. It scales whatever tempo is set for the sequencer (whether by tempo-change events or by one of the first two methods above). The default scalar is 1.0 (no change). Although this method causes the playback or recording to be faster or slower than the nominal tempo (unless the factor is 1.0), it doesn't alter the nominal tempo. In other words, the tempo values returned by <code>getTempoInBPM</code> and <code>getTempoInMPQ</code> are unaffected by the tempo factor, even though the tempo factor does affect the actual rate of playback or recording. Also, if the tempo is changed by a tempo-change event or by one of the first two methods, it still gets scaled by whatever tempo factor was last set. If you load a new sequence, however, the tempo factor is reset to 1.0. 
</p><p><a name="124703"> </a>
Note that all these tempo-change directives are ineffectual when the sequence's division type is one of the SMPTE types, instead of PPQ. 
</p><a name="124704"> </a>
<h4> Muting or Soloing Individual Tracks in the Sequence</h4>
<p><a name="124705"> </a>
It's often convenient for users of sequencers to be able to turn off certain tracks, to hear more clearly exactly what is happening in the music. A full-featured sequencer program lets the user choose which tracks should sound during playback. (Speaking more precisely, since sequencers don't actually create sound themselves, the user chooses which tracks will contribute to the stream of MIDI messages that the sequencer produces.) Typically, there are two types of graphical controls on each track: a <em>mute</em> button and a <em>solo</em> button. If the mute button is activated, that track will not sound under any circumstances, until the mute button is deactivated. Soloing is a less well-known feature. It's roughly the opposite of muting. If the solo button on any track is activated, only tracks whose solo buttons are activated will sound. This feature lets the user quickly audition a small number of tracks without having to mute all the other tracks. The mute button typically takes priority over the solo button: if both are activated, the track doesn't sound.
</p><p><a name="124706"> </a>
Using <code>Sequencer</code> methods, muting or soloing tracks (as well as querying a track's current mute or solo state) is easily accomplished. Let's assume we have obtained the default <code>Sequencer</code> and that we've loaded sequence data into it. Muting the fifth track in the sequence would be accomplished as follows:
</p><blockquote><pre>    sequencer.setTrackMute(4, true);
    boolean muted = sequencer.getTrackMute(4);
    if (!muted) { 
        return;		// muting failed
    }
</pre></blockquote>
There are a couple of things to note about the above code snippet. First, tracks of a sequence are numbered starting with 0 and ending with the total number of tracks minus 1. Also, the second argument to <code>setTrackMute</code> is a boolean. If it's true, the request is to mute the track;  otherwise the request is to unmute the specified track. Lastly, in order to test that the muting took effect, we invoke the <code>Sequencer getTrackMute</code> method, passing it the track number we're querying. If it returns<code> true</code>, as we'd expect in this case, then the mute request worked. If it returns <code>false</code>, then it failed. 
<p></p><p><a name="124713"> </a>
Mute requests may fail for various reasons. For example, the track number specified in the <code>setTrackMute</code> call might exceed the total number of tracks, or the sequencer might not support muting. By calling <code>getTrackMute</code>, we can determine if our request succeeded or failed.
</p><p><a name="124714"> </a>
As an aside, the boolean that's returned by <code>getTrackMute</code> can, indeed, tell us if a failure occurred, but it can't tell us why it occurred. We could test to see if a failure was caused by passing an invalid track number to the <code>setTrackMute</code> method. To do this, we would call the <code>getTracks</code> method of <code>Sequence</code>, which returns an array containing all of the tracks in the sequence. If the track number specified in the <code>setTrackMute</code> call exceeds the length of this array, then we know we specified an invalid track number.
</p><p><a name="124715"> </a>
If the mute request succeeded, then in our example, the fifth track will not sound when the sequence is playing, nor will any other tracks that are currently muted.
</p><p><a name="124716"> </a>
The method and techniques for soloing a track are very similar to those for muting. To solo a track, invoke the <code>setTrackSolo</code> method of <code>Sequence:</code>
<blockquote><pre>
void setTrackSolo(int track, boolean bSolo)
</pre></blockquote>
As in <code>setTrackMute</code>, the first argument specifies the zero-based track number, and the second argument, if <code>true</code>, specifies that the track should be in solo mode; otherwise the track should not be soloed.
<p></p><p><a name="124719"> </a>
By default, a track is neither muted nor soloed.
</p><a name="124721"> </a>
<h4> Synchronizing with Other MIDI Devices</h4>
<p><a name="124722"> </a>
<code>Sequencer</code> has an inner class called <code>Sequencer.SyncMode</code>. A <code>SyncMode</code> object represents one of the ways in which a MIDI sequencer's notion of time can be synchronized with a master or slave device. If the sequencer is being synchronized to a master, the sequencer revises its current time in response to certain MIDI messages from the master. If the sequencer has a slave, the sequencer similarly sends MIDI messages to control the slave's timing.
</p><p><a name="124723"> </a>
There are three predefined modes that specify possible masters for a sequencer: <code>INTERNAL_CLOCK</code>, <code>MIDI_SYNC</code>, and <code>MIDI_TIME_CODE</code>. The latter two work if the sequencer receives MIDI messages from another device. In these two modes, the sequencer's time gets reset based on system real-time timing clock messages or MIDI time code (MTC) messages, respectively. (See the MIDI specification for more information about these types of message.) These two modes can also be used as slave modes, in which case the sequencer sends the corresponding types of MIDI messages to its receiver. A fourth mode, <code>NO_SYNC</code>, is used to indicate that the sequencer should not send timing information to its receivers.
</p><p><a name="124724"> </a>
By calling the <code>setMasterSyncMode</code> method with a supported <code>SyncMode</code> object as the argument, you can specify how the sequencer's timing is controlled. Likewise, the <code>setSlaveSyncMode</code> method determines what timing information the sequencer will send to its receivers. This information controls the timing of devices that use the sequencer as a master timing source.
</p><a name="124725"> </a>
<h4> Specifying Special Event Listeners</h4>
<p><a name="124726"> </a>
Each track of a sequence can contain many different kinds of <code>MidiEvents</code>. Such events include Note On and Note Off messages, program changes, control changes, and meta events. The Java Sound API specifies "listener" interfaces for the last two of these event types (control change events and meta events). You can use these interfaces to receive notifications when such events occur during playback of a sequence.
</p><p><a name="124727"> </a>
Objects that support the <code>ControllerEventListener</code> interface can receive notification when a <code>Sequencer</code> processes particular control-change messages. A control-change message is a standard type of MIDI message that represents a change in the value of a MIDI controller, such as a pitch-bend wheel or a data slider. (See the MIDI specification for the complete list of control-change messages.) When such a message is processed during playback of a sequence, the message instructs any device (probably a synthesizer) that's receiving the data from the sequencer to update the value of some parameter. The parameter usually controls some aspect of sound synthesis, such as the pitch of the currently sounding notes if the controller was the pitch-bend wheel. When a sequence is being recorded, the control-change message means that a controller on the external physical device that created the message has been moved, or that such a move has been simulated in software.
</p><p><a name="124728"> </a>
Here's how the <code>ControllerEventListener</code> interface is used. Let's assume that you've developed a class that implements the <code>ControllerEventListener</code> interface, meaning that your class contains the following method:
</p><blockquote><pre>    void controlChange(ShortMessage msg)
</pre></blockquote>
Let's also assume that you've created an instance of your class and assigned it to a variable called <code>myListener</code>. If you include the following statements somewhere within your program: 
<blockquote><pre>
    int[] controllersOfInterest = { 1, 2, 4 };
    sequencer.addControllerEventListener(myListener,
        controllersOfInterest);
</pre></blockquote>
then your class's <code>controlChange</code> method will be invoked every time the sequencer processes a control-change message for MIDI controller numbers 1, 2, or 4. In other words, when the <code>Sequencer</code> processes a request to set the value of any of the registered controllers, the <code>Sequencer</code> will invoke your class's <code>controlChange</code> method. (Note that the assignments of MIDI controller numbers to specific control devices is detailed in the MIDI 1.0 Specification.)
<p></p><p><a name="124734"> </a>
The <code>controlChange </code>method is passed a <code>ShortMessage</code> containing the controller number affected, and the new value to which the controller was set. You can obtain the controller number using the <code>ShortMessage.getData1</code> method, and the new setting of the controller's value using the <code>ShortMessage.getData2</code> method.
</p><p><a name="124735"> </a>
The other kind of special event listener is defined by the <code>MetaEventListener</code> interface. Meta messages, according to the Standard MIDI Files 1.0 specification, are messages that are not present in MIDI wire protocol but that can be embedded in a MIDI file. They are not meaningful to a synthesizer, but can be interpreted by a sequencer. Meta messages include instructions (such as tempo change commands), lyrics or other text, and other indicators (such as end-of-track).
</p><p><a name="124736"> </a>
The <code>MetaEventListener</code> mechanism is analogous to <code>ControllerEventListener</code>. Implement the <code>MetaEventListener</code> interface in any class whose instances need to be notified when a <code>MetaMessage</code> is processed by the sequencer. This involves adding the following method to the class:
<blockquote><pre>void meta(MetaMessage msg)
</pre></blockquote>
<p><a name="124738"> </a>
You register an instance of this class by passing it as the argument to the <code>Sequencer addMetaEventListener</code> method:
<blockquote><pre>boolean b = sequencer.addMetaEventListener
        (myMetaListener);
</pre></blockquote>
This is slightly different from the approach taken by the <code>ControllerEventListener</code> interface, because you have to register to receive all <code>MetaMessages, </code>not just selected ones of interest. If the sequencer encounters a <code>MetaMessage</code> in its sequence, it will invoke <code>myMetaListener.meta</code>, passing it the <code>MetaMessage</code> encountered. The <code>meta</code> method can invoke <code>getType</code> on its <code>MetaMessage</code> argument to obtain an integer from 0 to 127 that indicates the message type, as defined by the Standard MIDI Files 1.0 specification. 
<p></p>
<p>&nbsp;</p></body>
</html>
